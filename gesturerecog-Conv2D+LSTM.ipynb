{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = './data/train'\n",
    "train_labels = './data/train.csv'\n",
    "val_data = './data/val'\n",
    "val_labels = './data/val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import GestureDataGenerator, plot_training_history, set_seed, get_callbacks, set_memorry_limit_for_tf\n",
    "set_seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_fraction = 1.0             # Full data load\n",
    "batch_size = 16                 # We are low on resources. We will go slow and steady.\n",
    "image_size = (120, 120)\n",
    "\n",
    "# Initialize the generator\n",
    "train_generator = GestureDataGenerator(\n",
    "    data_path=train_data,\n",
    "    labels_csv=train_labels,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    augmentations={\n",
    "        'rotation': 5,       # Rotate up to Â±5 degrees\n",
    "        'brightness': True,  # Random brightness adjustment\n",
    "        'contrast': True,    # Random contrast adjustment\n",
    "        'blur': True         # Apply Gaussian blur\n",
    "    },    \n",
    "    shuffle=True,\n",
    "    load_fraction=load_fraction,\n",
    "    debug=False,\n",
    "    use_mediapipe=False,\n",
    ")\n",
    "\n",
    "val_generator = GestureDataGenerator(\n",
    "    data_path=val_data,\n",
    "    labels_csv=val_labels,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    augmentations=None,\n",
    "    shuffle=False,\n",
    "    load_fraction=1.0,\n",
    "    debug=False,\n",
    "    use_mediapipe=False,\n",
    ")\n",
    "\n",
    "# Get the first batch\n",
    "X, y = train_generator[0]\n",
    "\n",
    "# Print outputs\n",
    "print(\"Input batch shape (X):\", X.shape)  # Expected shape: (batch_size, sequence_length, 224, 224, 3)\n",
    "print(\"Labels batch shape (y):\", y.shape)  # Expected shape: (batch_size, num_classes)\n",
    "print(\"First label in batch (one-hot):\", y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "sequence_length = train_generator.sequence_length  # Frames per video (from generator)\n",
    "image_size = train_generator.image_size            # Image size (height, width)\n",
    "num_classes = train_generator.num_classes          # Number of gesture classes\n",
    "input_shape = (sequence_length, image_size[0], image_size[1], 3)  # Conv3D input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, regularizers\n",
    "\n",
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    # Input layer\n",
    "    layers.Input(shape=input_shape),  # Input shape: (timesteps, height, width, channels)\n",
    "\n",
    "    # Smaller CNN layers for feature extraction\n",
    "    layers.TimeDistributed(layers.Conv2D(16, (3, 3), activation='relu', padding='same')),\n",
    "    layers.TimeDistributed(layers.BatchNormalization()),\n",
    "    layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2), padding='same')),\n",
    "\n",
    "    layers.TimeDistributed(layers.Conv2D(32, (3, 3), activation='relu', padding='same')),\n",
    "    layers.TimeDistributed(layers.BatchNormalization()),\n",
    "    layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2), padding='same')),\n",
    "\n",
    "    layers.TimeDistributed(layers.Conv2D(64, (3, 3), activation='relu', padding='same')),\n",
    "    layers.TimeDistributed(layers.BatchNormalization()),\n",
    "    layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2), padding='same')),\n",
    "\n",
    "    # Global average pooling to reduce parameters\n",
    "    layers.TimeDistributed(layers.GlobalAveragePooling2D()),\n",
    "\n",
    "    # RNN layer for temporal modeling\n",
    "    layers.Bidirectional(layers.GRU(32, return_sequences=False, recurrent_activation='sigmoid')),  # cuDNN-compatible configuration\n",
    "\n",
    "    # Fully connected layers\n",
    "    layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01)),  # L2 regularization\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    # Output layer\n",
    "    layers.Dense(num_classes, activation='softmax')  # Softmax for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_location = './best-models/Conv2D+LSTM.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback, reduce_lr_callback, early_stopping_callback = get_callbacks(filepath = model_save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_1 = model.fit(\n",
    "    x=train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    callbacks=[checkpoint_callback, reduce_lr_callback, early_stopping_callback],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(histories=[history_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(model_save_location)\n",
    "\n",
    "# # Train the model for more epochs\n",
    "# history_2 = model.fit(\n",
    "#     x=train_generator,\n",
    "#     validation_data=val_generator,\n",
    "#     epochs=30,                  # Train for more epochs\n",
    "#     initial_epoch=5,            # Start counting previous epochs\n",
    "#     callbacks=[checkpoint_callback, reduce_lr_callback, early_stopping_callback],\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# plot_training_history(histories=[history_1, history_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(model_save_location)\n",
    "\n",
    "# # Train the model for more epochs\n",
    "# history_3 = model.fit(\n",
    "#     x=train_generator,\n",
    "#     validation_data=val_generator,\n",
    "#     epochs=50,                   # Train for more epochs\n",
    "#     initial_epoch=30,            # Start counting previous epochs\n",
    "#     callbacks=[checkpoint_callback, reduce_lr_callback, early_stopping_callback],\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# plot_training_history(histories=[history_1, history_2, history_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_save_location)\n",
    "\n",
    "evaluation_results = model.evaluate(val_generator, verbose=1)\n",
    "\n",
    "for metric, value in zip(model.metrics_names, evaluation_results):\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
