{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = './data/val'\n",
    "test_labels = './data/val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download utilities.py\n",
    "import os\n",
    "import requests\n",
    "\n",
    "file_name = \"utilities.py\"\n",
    "url = \"https://raw.githubusercontent.com/mohiteamit/upGrad-Gesture-Recognition/refs/heads/main/utilities.py\"\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(file_name):\n",
    "    print(f\"{file_name} not found. Downloading...\")\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.ok:\n",
    "            with open(file_name, \"wb\") as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"{file_name} downloaded successfully.\")\n",
    "        else:\n",
    "            print(f\"Failed to download {file_name}. HTTP Status Code: {response.status_code}\")\n",
    "            exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {file_name}: {e}\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models downloaded.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# List of model URLs\n",
    "model_urls = [\n",
    "    \"https://github.com/mohiteamit/upGrad-Gesture-Recognition/raw/refs/heads/main/best-models/Conv2D+GRU.keras\",\n",
    "    \"https://github.com/mohiteamit/upGrad-Gesture-Recognition/raw/refs/heads/main/best-models/Conv2D+LSTM.keras\",\n",
    "    \"https://github.com/mohiteamit/upGrad-Gesture-Recognition/raw/refs/heads/main/best-models/Conv3D-32-64-128.keras\",\n",
    "    \"https://github.com/mohiteamit/upGrad-Gesture-Recognition/raw/refs/heads/main/best-models/pretrained-MobileNetV2+GRU.keras\",\n",
    "    \"https://github.com/mohiteamit/upGrad-Gesture-Recognition/raw/refs/heads/main/best-models/pretrained-MobileNetV3Small+GRU.keras\",\n",
    "    \"https://github.com/mohiteamit/upGrad-Gesture-Recognition/raw/refs/heads/main/best-models/pretrained-mediapipe+gru.keras\",\n",
    "]\n",
    "\n",
    "# Directory to save models\n",
    "output_dir = \"models_to_evaluate\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to verify file integrity\n",
    "def verify_file(file_path, url):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        local_content = f.read()\n",
    "    response = requests.get(url)\n",
    "    return response.ok and local_content == response.content\n",
    "\n",
    "# Download models\n",
    "for url in model_urls:\n",
    "    filename = os.path.join(output_dir, os.path.basename(url))\n",
    "    try:\n",
    "        if not os.path.exists(filename) or not verify_file(filename, url):\n",
    "            response = requests.get(url)\n",
    "            if response.ok:\n",
    "                with open(filename, 'wb') as f:\n",
    "                    f.write(response.content)\n",
    "            else:\n",
    "                print(f\"Failed to download: {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {url}: {e}\")\n",
    "\n",
    "print(\"Models downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mediapipe module not found. Skipping...\n"
     ]
    }
   ],
   "source": [
    "from utilities import GestureDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 batches created, each of size 8, with 100 sequences of 30 images each. Use MediaPipe: False\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_70 (TimeDi  (None, 30, None, None, 1  448      \n",
      " stributed)                  6)                                  \n",
      "                                                                 \n",
      " time_distributed_71 (TimeDi  (None, 30, None, None, 1  64       \n",
      " stributed)                  6)                                  \n",
      "                                                                 \n",
      " time_distributed_72 (TimeDi  (None, 30, None, None, 1  0        \n",
      " stributed)                  6)                                  \n",
      "                                                                 \n",
      " time_distributed_73 (TimeDi  (None, 30, None, None, 3  4640     \n",
      " stributed)                  2)                                  \n",
      "                                                                 \n",
      " time_distributed_74 (TimeDi  (None, 30, None, None, 3  128      \n",
      " stributed)                  2)                                  \n",
      "                                                                 \n",
      " time_distributed_75 (TimeDi  (None, 30, None, None, 3  0        \n",
      " stributed)                  2)                                  \n",
      "                                                                 \n",
      " time_distributed_76 (TimeDi  (None, 30, None, None, 6  18496    \n",
      " stributed)                  4)                                  \n",
      "                                                                 \n",
      " time_distributed_77 (TimeDi  (None, 30, None, None, 6  256      \n",
      " stributed)                  4)                                  \n",
      "                                                                 \n",
      " time_distributed_78 (TimeDi  (None, 30, None, None, 6  0        \n",
      " stributed)                  4)                                  \n",
      "                                                                 \n",
      " time_distributed_79 (TimeDi  (None, 30, 64)           0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 64)               18816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,333\n",
      "Trainable params: 47,109\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "13/13 [==============================] - 24s 2s/step - loss: 0.3106 - accuracy: 0.9400\n",
      "loss: 0.3106\n",
      "accuracy: 0.9400\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.10\"):\n",
    "    image_size = (120, 120)\n",
    "\n",
    "    test_generator = GestureDataGenerator(\n",
    "        data_path=test_data,\n",
    "        labels_csv=test_labels,\n",
    "        image_size=image_size\n",
    "    )\n",
    "\n",
    "    Conv2D_GRU = load_model('models_to_evaluate/Conv2D+GRU.keras')                   # Best image size 120x120\n",
    "    Conv2D_GRU.summary()\n",
    "    evaluation_results = Conv2D_GRU.evaluate(test_generator)\n",
    "    for metric, value in zip(Conv2D_GRU.metrics_names, evaluation_results):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "else:\n",
    "    raise ValueError(\"This model requires TensorFlow 2.10.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 batches created, each of size 8, with 100 sequences of 30 images each. Use MediaPipe: False\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_50 (TimeDi  (None, 30, None, None, 1  448      \n",
      " stributed)                  6)                                  \n",
      "                                                                 \n",
      " time_distributed_51 (TimeDi  (None, 30, None, None, 1  64       \n",
      " stributed)                  6)                                  \n",
      "                                                                 \n",
      " time_distributed_52 (TimeDi  (None, 30, None, None, 1  0        \n",
      " stributed)                  6)                                  \n",
      "                                                                 \n",
      " time_distributed_53 (TimeDi  (None, 30, None, None, 3  4640     \n",
      " stributed)                  2)                                  \n",
      "                                                                 \n",
      " time_distributed_54 (TimeDi  (None, 30, None, None, 3  128      \n",
      " stributed)                  2)                                  \n",
      "                                                                 \n",
      " time_distributed_55 (TimeDi  (None, 30, None, None, 3  0        \n",
      " stributed)                  2)                                  \n",
      "                                                                 \n",
      " time_distributed_56 (TimeDi  (None, 30, None, None, 6  18496    \n",
      " stributed)                  4)                                  \n",
      "                                                                 \n",
      " time_distributed_57 (TimeDi  (None, 30, None, None, 6  256      \n",
      " stributed)                  4)                                  \n",
      "                                                                 \n",
      " time_distributed_58 (TimeDi  (None, 30, None, None, 6  0        \n",
      " stributed)                  4)                                  \n",
      "                                                                 \n",
      " time_distributed_59 (TimeDi  (None, 30, 64)           0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 64)               18816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,333\n",
      "Trainable params: 47,109\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "13/13 [==============================] - 6s 380ms/step - loss: 0.3660 - accuracy: 0.9100\n",
      "loss: 0.3660\n",
      "accuracy: 0.9100\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.10\"):\n",
    "    image_size = (120, 120)\n",
    "\n",
    "    test_generator = GestureDataGenerator(\n",
    "        data_path=test_data,\n",
    "        labels_csv=test_labels,\n",
    "        image_size=image_size\n",
    "    )\n",
    "\n",
    "    Conv2D_LSTM = load_model('models_to_evaluate/Conv2D+LSTM.keras')                   # Best image size 120x120\n",
    "    Conv2D_LSTM.summary()\n",
    "    evaluation_results = Conv2D_LSTM.evaluate(test_generator)\n",
    "    for metric, value in zip(Conv2D_LSTM.metrics_names, evaluation_results):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "else:\n",
    "    raise ValueError(\"This model requires TensorFlow 2.10.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 batches created, each of size 8, with 100 sequences of 30 images each. Use MediaPipe: False\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_3 (Conv3D)           (None, 30, 200, 200, 32)  2624      \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 15, 100, 100, 32)  0        \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_4 (Conv3D)           (None, 15, 100, 100, 64)  55360     \n",
      "                                                                 \n",
      " max_pooling3d_3 (MaxPooling  (None, 8, 50, 50, 64)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 8, 50, 50, 128)    221312    \n",
      "                                                                 \n",
      " global_average_pooling3d_1   (None, 128)              0         \n",
      " (GlobalAveragePooling3D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 296,453\n",
      "Trainable params: 296,453\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "13/13 [==============================] - 6s 458ms/step - loss: 0.3709 - accuracy: 0.8900\n",
      "loss: 0.3709\n",
      "accuracy: 0.8900\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.10\"):\n",
    "    image_size = (200, 200)\n",
    "\n",
    "    test_generator = GestureDataGenerator(\n",
    "        data_path=test_data,\n",
    "        labels_csv=test_labels,\n",
    "        image_size=image_size\n",
    "    )\n",
    "    Conv3D_32_64_128 = load_model('models_to_evaluate/Conv3D-32-64-128.keras')                   # Best image size 120x120\n",
    "    Conv3D_32_64_128.summary()\n",
    "    evaluation_results = Conv3D_32_64_128.evaluate(test_generator)\n",
    "    for metric, value in zip(Conv3D_32_64_128.metrics_names, evaluation_results):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "else:\n",
    "    raise ValueError(\"This model requires TensorFlow 2.10.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 batches created, each of size 8, with 100 sequences of 30 images each. Use MediaPipe: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"GRU_Gesture_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"GRU_Gesture_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Flatten_Keypoints               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Flatten_Keypoints               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m63\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_Layer (\u001b[38;5;33mGRU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_Layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,093</span> (98.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,093\u001b[0m (98.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,093</span> (98.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,093\u001b[0m (98.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 6s/step - accuracy: 0.9940 - loss: 0.0864\n",
      "loss: 0.0864\n",
      "compile_metrics: 0.9900\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.18\"):\n",
    "    image_size = (256, 256)\n",
    "\n",
    "    test_generator = GestureDataGenerator(\n",
    "        data_path=test_data,\n",
    "        labels_csv=test_labels,\n",
    "        image_size=image_size,\n",
    "        use_mediapipe=True\n",
    "    )\n",
    "\n",
    "    mediapipe_GRU = load_model('models_to_evaluate/pretrained-mediapipe+gru.keras')                   # Best image size 120x120\n",
    "    mediapipe_GRU.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    mediapipe_GRU.summary()\n",
    "    evaluation_results = mediapipe_GRU.evaluate(test_generator)\n",
    "    for metric, value in zip(mediapipe_GRU.metrics_names, evaluation_results):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "else:\n",
    "    raise ValueError(\"This model requires TensorFlow 2.18.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 batches created, each of size 8, with 100 sequences of 30 images each. Use MediaPipe: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_GRU_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN_GRU_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ CNN_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling_Layer                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11520</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,109,184</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ CNN_Layer (\u001b[38;5;33mTimeDistributed\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m) │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling_Layer                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1280\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten_Layer (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m11520\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_Layer (\u001b[38;5;33mGRU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │     \u001b[38;5;34m1,109,184\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_Layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m165\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,367,339</span> (12.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,367,339\u001b[0m (12.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,109,349</span> (4.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,109,349\u001b[0m (4.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.8174 - loss: 0.8290\n",
      "loss: 0.8503\n",
      "compile_metrics: 0.8200\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.18\"):\n",
    "    image_size = (224, 224)\n",
    "\n",
    "    test_generator = GestureDataGenerator(\n",
    "        data_path=test_data,\n",
    "        labels_csv=test_labels,\n",
    "        image_size=image_size,\n",
    "        use_mediapipe=False\n",
    "    )\n",
    "\n",
    "    MobileNetV2_GRU = load_model('models_to_evaluate/pretrained-MobileNetV2+GRU.keras')                   # Best image size 120x120\n",
    "    MobileNetV2_GRU.summary()\n",
    "    evaluation_results = MobileNetV2_GRU.evaluate(test_generator)\n",
    "    for metric, value in zip(MobileNetV2_GRU.metrics_names, evaluation_results):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    else:\n",
    "        raise ValueError(\"This model requires TensorFlow 2.18.x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 batches created, each of size 8, with 100 sequences of 30 images each. Use MediaPipe: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_GRU_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN_GRU_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ CNN_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling_Layer                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5184</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,008,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ CNN_Layer (\u001b[38;5;33mTimeDistributed\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m)  │       \u001b[38;5;34m939,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MaxPooling_Layer                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m576\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Flatten_Layer (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m5184\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ GRU_Layer (\u001b[38;5;33mGRU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m1,008,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Dropout_Layer (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,964,101</span> (15.12 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,964,101\u001b[0m (15.12 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,008,325</span> (3.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,008,325\u001b[0m (3.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> (3.58 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m939,120\u001b[0m (3.58 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,016,656</span> (7.69 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,016,656\u001b[0m (7.69 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.3608 - loss: 1.4221\n",
      "loss: 1.4710\n",
      "compile_metrics: 0.3600\n"
     ]
    }
   ],
   "source": [
    "if tf.__version__.startswith(\"2.18\"):\n",
    "    image_size = (224, 224)\n",
    "\n",
    "    test_generator = GestureDataGenerator(\n",
    "        data_path=test_data,\n",
    "        labels_csv=test_labels,\n",
    "        image_size=image_size,\n",
    "        use_mediapipe=False\n",
    "    )\n",
    "\n",
    "    MobileNetV3Small_GRU = load_model('models_to_evaluate/pretrained-MobileNetV3Small+GRU.keras')                   # Best image size 120x120\n",
    "    MobileNetV3Small_GRU.summary()\n",
    "    evaluation_results = MobileNetV3Small_GRU.evaluate(test_generator)\n",
    "    for metric, value in zip(MobileNetV3Small_GRU.metrics_names, evaluation_results):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "else:\n",
    "    raise ValueError(\"This model requires TensorFlow 2.18.x\")        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
